{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM/DnNnQhQuCef1ThRuM4sr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"72f8b1c538dd4da5ad25743b3bab358f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05efb8527ebd4092870f35699ffc63ac","IPY_MODEL_1fdff0a5c98b45a5ba4610c0340ec59a","IPY_MODEL_bfe1bd8987f7496ca8e53655364f3dec"],"layout":"IPY_MODEL_3f5a5513fdcb48e78e490260e0df8473"}},"05efb8527ebd4092870f35699ffc63ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6525206e95440ae860a68f80d437532","placeholder":"​","style":"IPY_MODEL_538afcf09a4947ed8e8485fb230aad4d","value":"Loading checkpoint shards: 100%"}},"1fdff0a5c98b45a5ba4610c0340ec59a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_243b88ca54a046cba06721e9c3f34e37","max":41,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60371a419d20403fbda5c7261077f8dd","value":41}},"bfe1bd8987f7496ca8e53655364f3dec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbc93b8a634b4a938bffba206cc02d99","placeholder":"​","style":"IPY_MODEL_43e3500bafe840c0a43bb0ee929ff361","value":" 41/41 [03:32&lt;00:00,  4.81s/it]"}},"3f5a5513fdcb48e78e490260e0df8473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6525206e95440ae860a68f80d437532":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"538afcf09a4947ed8e8485fb230aad4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"243b88ca54a046cba06721e9c3f34e37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60371a419d20403fbda5c7261077f8dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbc93b8a634b4a938bffba206cc02d99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43e3500bafe840c0a43bb0ee929ff361":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Large Language Models\n","\n","사용자 입력에 대한 응답 생성 모델\n","\n","![](https://github.com/nlpai-lab/KULLM/raw/master/assets/example.png)"],"metadata":{"id":"WzEfXwWUwBZ2"}},{"cell_type":"markdown","source":["# ChatGPT API\n","\n","1. API 발급\n","    - https://platform.openai.com/account/api-keys\n","    - 카드 등록 후 유료 사용, 월별 청구, [가격](https://openai.com/pricing)\n","    - [토큰 수 계산](https://platform.openai.com/tokenizer)\n","    - API 키는 한 번 발급 후 다시 보이지 않으므로 잘 보관\n","    - 유출될 경우 다른 사람의 의해 비용이 청구될 수 있으니 주의!\n","2. Create new secret key 버튼 클릭\n","3. 코딩!"],"metadata":{"id":"20qD5UOxY_qY"}},{"cell_type":"markdown","source":["## 패키지 설치"],"metadata":{"id":"K9nDYrdwF9Sm"}},{"cell_type":"code","source":["!pip install -q openai gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCXa1rJbZB5L","executionInfo":{"status":"ok","timestamp":1689335036151,"user_tz":-540,"elapsed":18060,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}},"outputId":"5cc7fde5-1b90-4367-de2f-db43698a65b3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["## API 키 입력"],"metadata":{"id":"NMo7TIqpGYOI"}},{"cell_type":"code","source":["import openai\n","\n","openai.api_key = \"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\""],"metadata":{"id":"0s8iFDC2GIPH","executionInfo":{"status":"ok","timestamp":1689335062080,"user_tz":-540,"elapsed":287,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## 답변 생성 함수\n","\n","1. role: 역할\n","    - system: 전체적인 역할\n","    - user: 사용자\n","    - assistant: ChatGPT\n","2. content: 내용"],"metadata":{"id":"PJqwYm5pHSRv"}},{"cell_type":"code","source":["def gen(x):\n","    gpt_prompt = [{\n","        \"role\": \"system\",\n","        \"content\": \"당신은 친절한 인공지능 챗봇입니다. 입력에 대해 짧고 간결하고 친절하게 대답해주세요.\"\n","    }]\n","\n","    gpt_prompt.append({\n","        \"role\": \"user\",\n","        \"content\": x\n","    })\n","\n","\n","    gpt_response = openai.ChatCompletion.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=gpt_prompt\n","    )\n","\n","    return gpt_response[\"choices\"][0][\"message\"][\"content\"]"],"metadata":{"id":"_IEuOwzrGW5C","executionInfo":{"status":"ok","timestamp":1689335263455,"user_tz":-540,"elapsed":2,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## 테스트"],"metadata":{"id":"VkzL2LN8HUgS"}},{"cell_type":"code","source":["gen(\"안녕하세요, 당신은 누구입니까?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"tEpnqZL7HXBV","executionInfo":{"status":"ok","timestamp":1689335276545,"user_tz":-540,"elapsed":2286,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}},"outputId":"43410c32-7fd3-47b6-a3fe-4cd428d3d2da"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'안녕하세요! 저는 친절한 인공지능 챗봇입니다. 무엇을 도와드릴까요?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["gen(\"ChatGPT는 무엇입니까?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"AJi8o-H3Os0l","executionInfo":{"status":"ok","timestamp":1689335305089,"user_tz":-540,"elapsed":5180,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}},"outputId":"aade13b2-3071-4616-9973-95833fc4f3d1"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ChatGPT는 OpenAI에서 개발한 자연어 처리 모델입니다. 이 모델은 대화형 방식으로 텍스트 기반의 질문에 응답할 수 있습니다. ChatGPT는 다양한 주제에 대해 정보를 제공하고, 조언을 제공하며, 일상적인 대화를 할 수 있습니다. 저는 ChatGPT의 한 예시로서 여러분을 도와드릴 수 있습니다. 무엇을 도와드릴까요?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## [간단] Gradio"],"metadata":{"id":"fNv3xTSDKB0l"}},{"cell_type":"code","source":["import gradio as gr\n","\n","def inference(text):\n","    return gen(text)\n","\n","demo = gr.Interface(fn=inference, inputs=\"text\", outputs=\"text\")\n","\n","demo.launch(debug=True, share=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":626},"id":"0CVn_-LYKILK","executionInfo":{"status":"ok","timestamp":1689335510058,"user_tz":-540,"elapsed":60004,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}},"outputId":"a6c4c77a-6986-49b4-d075-35865c4c88b3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://d536a8edc29363f2af.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://d536a8edc29363f2af.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://d536a8edc29363f2af.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## 맥락 기억"],"metadata":{"id":"Mfa0rcBiKfSH"}},{"cell_type":"code","source":["gpt_prompt = [{\n","    \"role\": \"system\",\n","    \"content\": \"당신은 친절한 인공지능 챗봇입니다. 입력에 대해 짧고 간결하고 친절하게 대답해주세요.\",\n","}, {\n","    \"role\": \"user\",\n","    \"content\": \"여름에 먹기 좋은 과일 추천해줘\",\n","}, {\n","    \"role\": \"assistant\",\n","    \"content\": \"여름에는 수박, 참외, 복숭아, 망고, 파인애플 등이 시원하고 맛있게 먹을 수 있는 과일입니다.\",\n","}, {\n","    \"role\": \"user\",\n","    \"content\": \"위 문장으로 영어로 번역해줘\",\n","}]\n","\n","gpt_response = openai.ChatCompletion.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=gpt_prompt\n",")\n","\n","gpt_response[\"choices\"][0][\"message\"][\"content\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"xMJjYQidKhUp","executionInfo":{"status":"ok","timestamp":1689335686278,"user_tz":-540,"elapsed":1927,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}},"outputId":"499d2836-5415-4fae-90f1-a1fe706503a7"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'I recommend watermelon, honeydew melon, peach, mango, and pineapple as fruits that are refreshing and delicious to eat in the summer.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## [챗봇] Gradio\n","\n","- 맥락 기억"],"metadata":{"id":"iStPm2E4KGWY"}},{"cell_type":"code","source":["import gradio as gr\n","\n","def predict(input, history):\n","    history.append({\"role\": \"user\", \"content\": input})\n","\n","    gpt_response = openai.ChatCompletion.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=history\n","    )\n","\n","    response = gpt_response[\"choices\"][0][\"message\"][\"content\"]\n","\n","    history.append({\"role\": \"assistant\", \"content\": response})\n","\n","    messages = [(history[i][\"content\"], history[i+1][\"content\"]) for i in range(1, len(history), 2)]\n","\n","    return messages, history\n","\n","\n","with gr.Blocks() as demo:\n","    chatbot = gr.Chatbot(label=\"ChatBot\")\n","\n","    state = gr.State([{\n","        \"role\": \"system\",\n","        \"content\": \"당신은 친절한 인공지능 챗봇입니다. 입력에 대해 짧고 간결하고 친절하게 대답해주세요.\"\n","    }])\n","\n","    with gr.Row():\n","        txt = gr.Textbox(show_label=False, placeholder=\"챗봇에게 아무거나 물어보세요\").style(container=False)\n","\n","    txt.submit(predict, [txt, state], [chatbot, state])\n","\n","demo.launch(debug=True, share=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":660},"id":"i_3TYdkmILuG","executionInfo":{"status":"ok","timestamp":1689336039251,"user_tz":-540,"elapsed":335503,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}},"outputId":"50778f6e-3290-404a-8ae7-137f0e3bbae3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-26537bf1d8fe>:29: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n","  txt = gr.Textbox(show_label=False, placeholder=\"챗봇에게 아무거나 물어보세요\").style(container=False)\n"]},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://46ca69d66530594258.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://46ca69d66530594258.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://46ca69d66530594258.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"CklTi0WJHf_c"}},{"cell_type":"markdown","source":["# [참고] 로컬에 설치하여 사용하기"],"metadata":{"id":"u3u0A35ZY390"}},{"cell_type":"markdown","source":["## GPU 사용\n","\n","1. 메뉴 - 런타임 - 런타임 유형 변경\n","2. 하드웨어 가속기 - GPU 선택\n","3. 저장"],"metadata":{"id":"UU6ZNinGwR7W"}},{"cell_type":"markdown","source":["## 패키지 설치"],"metadata":{"id":"dmc2j48vwloJ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reaouszRrjMW","executionInfo":{"status":"ok","timestamp":1685746064018,"user_tz":-540,"elapsed":15659,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}},"outputId":"a004fb06-9ed6-4da9-c9c7-c7dee63c2de6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -Uq transformers tokenizers accelerate safetensors bitsandbytes peft loralib sentencepiece gradio"]},{"cell_type":"markdown","source":["## 모델 로드\n","\n","### KoAlpaca\n","\n","- HuggingFace: https://huggingface.co/beomi/KoAlpaca-KoRWKV-6B\n","- GitHub: https://github.com/Beomi/KoAlpaca\n","\n","<img src=\"https://user-images.githubusercontent.com/11323660/226633444-40f0a6b1-1a04-4659-a2ea-bef7e9d22bb4.png\" height=\"500px\">"],"metadata":{"id":"W2-RDcbpEJaH"}},{"cell_type":"code","source":["from peft import PeftModel\n","from transformers import LlamaTokenizer, LlamaForCausalLM\n","\n","base = 'decapoda-research/llama-13b-hf'\n","finetuned = 'beomi/KoAlpaca-13B-LoRA'\n","\n","tokenizer = LlamaTokenizer.from_pretrained(base)\n","tokenizer.pad_token_id = 0\n","tokenizer.padding_side = \"left\"\n","\n","model = LlamaForCausalLM.from_pretrained(\n","    base,\n","    load_in_8bit=True,\n","    device_map=\"auto\",\n",")\n","\n","model = PeftModel.from_pretrained(model, finetuned, device_map={'': 0})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":659,"referenced_widgets":["72f8b1c538dd4da5ad25743b3bab358f","05efb8527ebd4092870f35699ffc63ac","1fdff0a5c98b45a5ba4610c0340ec59a","bfe1bd8987f7496ca8e53655364f3dec","3f5a5513fdcb48e78e490260e0df8473","c6525206e95440ae860a68f80d437532","538afcf09a4947ed8e8485fb230aad4d","243b88ca54a046cba06721e9c3f34e37","60371a419d20403fbda5c7261077f8dd","cbc93b8a634b4a938bffba206cc02d99","43e3500bafe840c0a43bb0ee929ff361"]},"id":"0usyZg73DYyk","executionInfo":{"status":"ok","timestamp":1685747312939,"user_tz":-540,"elapsed":263058,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}},"outputId":"360fe256-8cdc-4494-8962-93530be4e355"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===================================BUG REPORT===================================\n","Welcome to bitsandbytes. For bug reports, please run\n","\n","python -m bitsandbytes\n","\n"," and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n","================================================================================\n","bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n","CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n","CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n","CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n","CUDA SETUP: Detected CUDA version 118\n","CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('8013'), PosixPath('//172.28.0.1'), PosixPath('http')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-ovirimre1gjz --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n","Either way, this might cause trouble in the future:\n","If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n","  warn(msg)\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n","The class this function is called from is 'LlamaTokenizer'.\n","Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/41 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72f8b1c538dd4da5ad25743b3bab358f"}},"metadata":{}}]},{"cell_type":"code","source":["def gen(x, max_new_tokens=128, temperature=0.7):\n","    prompt = f\"\"\"인사에는 짧고 간단한 친절한 인사로 답하고, 아래 대화에 간단하고 짧게 답해주세요.\n","\n","### Instruction: {x}\n","\n","### Response:\"\"\"\n","\n","    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to('cuda:0')\n","\n","    gen_tokens = model.generate(\n","        input_ids=input_ids,\n","        max_new_tokens=max_new_tokens,\n","        num_return_sequences=1,\n","        temperature=temperature,\n","        no_repeat_ngram_size=6,\n","        do_sample=True,\n","    )\n","\n","    gen_text = tokenizer.decode(gen_tokens[0], skip_special_tokens=True)\n","\n","    return gen_text.replace(prompt, '')"],"metadata":{"id":"PejwoldyGRzy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gen(\"안녕하세요\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Khtvgr5QXomo","executionInfo":{"status":"ok","timestamp":1685747702147,"user_tz":-540,"elapsed":46259,"user":{"displayName":"Taehee Lee","userId":"12017922817927484990"}},"outputId":"f13f3f89-583c-4b9a-c9d7-01ad744fb6cf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' 안념하세요\\n\\n저는 반드시 처음 안녕히든요. 저는 귀하를 추측하려고 하지만 이 형편 비지니스 모드를 작성했습니다. 먼저, 테스트 코드를 생성하고 실'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]}]}